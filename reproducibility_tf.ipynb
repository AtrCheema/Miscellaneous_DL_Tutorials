{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "tensor-flow-2-2",
      "graded_item_id": "2x3vn",
      "launcher_item_id": "QKXZc"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "reproducibility_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtrCheema/Miscellaneous_DL_Tutorials/blob/master/reproducibility_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rb7uTGx0QMR"
      },
      "source": [
        "Question: Is it possible to reproduce the results from models built using `tensorflow`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEnfEUIgRqlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347618f8-90ea-46a5-d403-19794180cbee"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "print(tf.__version__)\n",
        "\n",
        "# should be put before setting random seed for reproducability\n",
        "#tf.compat.v1.disable_eager_execution()  # even if this is put here, enabeling eager execution removes reproducability within one runtime. \n",
        "# With eager execution disabled, we have to restart runtime, if we want to reproduce results.\n",
        "# However, when eager execution is enabled (default mode) we can reproduce results just be resetting the seed"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijrYZ-HUYTKe"
      },
      "source": [
        "Gblobal parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4oa8o4jVZMv"
      },
      "source": [
        "ins = 3\n",
        "outs = 1\n",
        "lookback = 10\n",
        "bs = 3 \n",
        "filters = 65\n",
        "ks = 2\n",
        "samples = 100"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD0zNByZYXPu"
      },
      "source": [
        "Build a toy network consiting of LSTM and 1 dimensional convolutional neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5nj34caWeAn"
      },
      "source": [
        "def build_model(lstm_units=64, dropout=0.0, rec_dropout=0.0, lstm_act='tanh'):\n",
        "\n",
        "    tf_in = tf.keras.layers.Input(shape=(lookback, ins))\n",
        "    lstm_out = tf.keras.layers.LSTM(lstm_units,\n",
        "                                    activation = lstm_act,\n",
        "                                    return_sequences=True,\n",
        "                                    dropout=dropout,\n",
        "                                    recurrent_dropout=rec_dropout)(tf_in)\n",
        "    lstm_out = tf.keras.layers.Dropout(0.2)(lstm_out)\n",
        "    cnn_out = tf.keras.layers.Conv1D(filters, ks)(lstm_out)\n",
        "    max_pool = tf.keras.layers.MaxPool1D()(cnn_out)\n",
        "    max_pool = tf.keras.layers.Flatten()(max_pool)\n",
        "    pred = tf.keras.layers.Dense(outs)(max_pool)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=tf_in, outputs=pred)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtHWjekrR-2Y"
      },
      "source": [
        "def reset_seed(seed=313): \n",
        "    # fixing the seed so that we get same results.\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0nOrugP0qJZ"
      },
      "source": [
        "Runing the following cell, should reproduce the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hHPZXW2iA6p",
        "outputId": "77c59a48-ca41-4818-d73f-4c71b3129d88"
      },
      "source": [
        "reset_seed()\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs[0:10])\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size = bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "[[0.96603114]\n",
            " [0.25158145]\n",
            " [0.6336193 ]\n",
            " [0.87699084]\n",
            " [0.12521443]\n",
            " [0.58267236]\n",
            " [0.3706229 ]\n",
            " [0.44818863]\n",
            " [0.52849145]\n",
            " [0.41808173]]\n",
            "Model: \"functional_63\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_33 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_61 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.1309\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0804\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0885\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0841\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0801\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0755\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0813\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0787\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0766\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c8ecbc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQjJAEhpThaR"
      },
      "source": [
        "\n",
        "using `dropout` within LSTM does not causes reproducibility to vanish.\n",
        "\n",
        "Run following cell multiple times to check.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baZ6_h89TNgm",
        "outputId": "b318c722-c87e-4ae5-98c5-7b4648319394"
      },
      "source": [
        "seed = 313\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(dropout=0.5)\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size = bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_85\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_44 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_72 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.1458\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0876\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0952\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0904\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0882\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0849\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0862\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0839\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0885\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c8a12f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9LNupg5T_UJ"
      },
      "source": [
        "\n",
        "using `recurrent_dropout` within LSTM also retains reproducibility.\n",
        "\n",
        "Run following cell multiple times to check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqPYxtmOiCdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead3434b-ad82-4fd8-a556-4f1b435c3d9d"
      },
      "source": [
        "seed = 313\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(rec_dropout=0.4)\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size = bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_73\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_38 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_66 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.1311\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0807\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0869\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0846\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0800\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0745\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0816\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0771\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0765\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c756a7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62SWszl5UmMx"
      },
      "source": [
        "\n",
        "using `dropout` and `recurrent_dropout` simultaneously within LSTM causes reproducibility to vanish.\n",
        "\n",
        "Run following cell multiple times, and we see different results every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sOrc9iQSOnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e012fb27-4ce9-4505-993e-ca1d4efe9bbe"
      },
      "source": [
        "seed = 313\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(dropout=.2, rec_dropout=0.4)\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size=bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_77\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_40 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_68 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1327\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0859\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0874\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0886\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0864\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0803\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0886\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0868\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0840\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c6a23588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqUzfAgFarts"
      },
      "source": [
        "Although using `dropout` only without `recurrent_dropout` keeps reproducibility however, if we use `dropout` with `activation=relu`, it also causes reproduces reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21sX2KyJS2jM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a802d35e-972c-460d-94b4-1480a0018bd0"
      },
      "source": [
        "seed = 313\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(dropout=0.2, lstm_act='relu')\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size=bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_95\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_49 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_77 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_17 (MaxPooling (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.1327\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0809\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0906\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0826\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0788\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0752\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0777\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0780\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0750\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c45976a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF-gd362bWUk"
      },
      "source": [
        "We can see that simply using `activation=relu`, still retains reproducibility. It is only the combination of `activation=relu` and `dropout>0.0` which causes reproducibility to go away.\n",
        "\n",
        "The following cell on multiple runs, should give same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM9fjlPqTDv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60150130-c561-4e8a-8ccb-8f470f362008"
      },
      "source": [
        "seed = 313\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(lstm_act='relu')\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size=bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_101\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_52 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_80 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.1327\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0809\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0906\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0826\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0788\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0752\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0777\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0780\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0750\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c3c13588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gojiMHUTcXIz"
      },
      "source": [
        "Using `activation=relu` along with `recurrent_dropout>0.0` also retains reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpewThnOb6ob",
        "outputId": "b0186482-c755-4508-d1a5-f651434ca2b3"
      },
      "source": [
        "seed = 313\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(rec_dropout=0.2, lstm_act='relu')\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size=bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_109\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_56 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_84 (LSTM)               (None, 10, 64)            17408     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 10, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 9, 65)             8385      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_24 (MaxPooling (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 26,054\n",
            "Trainable params: 26,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.1331\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0817\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0903\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0828\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0787\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0757\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0781\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0784\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0760\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9c28cb5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtudodiCgtwx"
      },
      "source": [
        "changing all of them at the same time, should definitely result in different results on each return."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87gN9mAvdQT6",
        "outputId": "5091f363-913e-4c7e-d200-8f5181c9a476"
      },
      "source": [
        "reset_seed()\n",
        "\n",
        "inputs = np.random.random((samples, lookback, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model(dropout=0.3, rec_dropout=0.4, lstm_act='relu')\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size=bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1530.9009006470824\n",
            "51.74373624229513\n",
            "Model: \"functional_133\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_68 (InputLayer)        [(None, 10, 3)]           0         \n",
            "_________________________________________________________________\n",
            "lstm_96 (LSTM)               (None, 10, 128)           67584     \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 9, 65)             16705     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_36 (MaxPooling (None, 4, 65)             0         \n",
            "_________________________________________________________________\n",
            "flatten_36 (Flatten)         (None, 260)               0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 1)                 261       \n",
            "=================================================================\n",
            "Total params: 84,550\n",
            "Trainable params: 84,550\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.1265\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0874\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0908\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0872\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0842\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0816\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0823\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 1s 18ms/step - loss: 0.0815\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0841\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 1s 19ms/step - loss: 0.0858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9be6397b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP9HbydOlk_M"
      },
      "source": [
        "Let's build a different model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol9HWuO9jXMO"
      },
      "source": [
        "sub_seq = 3\n",
        "sub_seq_lens = int(lookback / sub_seq)\n",
        "\n",
        "def build_model2(lstm_units=64, dropout=0.0, rec_dropout=0.0, lstm_act='tanh'):\n",
        "\n",
        "    tf_in = tf.keras.layers.Input(shape=(sub_seq, 1, sub_seq_lens, ins))\n",
        "    convlstm2d_out = tf.keras.layers.ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu')(tf_in)\n",
        "    flat_out = tf.keras.layers.Flatten()(convlstm2d_out)\n",
        "    rpt_out = tf.keras.layers.RepeatVector(n=1)(flat_out)\n",
        "    lstm_out = tf.keras.layers.LSTM(units=lstm_units, activation=lstm_act, dropout=dropout, recurrent_dropout=rec_dropout)(rpt_out)\n",
        "    pred = tf.keras.layers.Dense(1)(lstm_out)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=tf_in, outputs=pred)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCTiZ1Eklsxz"
      },
      "source": [
        "As per our previous experience, running the folloing code repeatedly, we should expect different results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coujTpjHdWXS",
        "outputId": "b5f9e45d-8dc3-4224-98d7-cdb79501935a"
      },
      "source": [
        "reset_seed()\n",
        "\n",
        "inputs = np.random.random((samples, sub_seq, 1, sub_seq_lens, ins))\n",
        "print(inputs.sum())\n",
        "\n",
        "outputs = np.random.random((samples, outs))\n",
        "print(outputs.sum())\n",
        "\n",
        "model = build_model2(dropout=0.3, rec_dropout=0.4, lstm_act='relu')\n",
        "\n",
        "model.fit(inputs,\n",
        "          outputs,\n",
        "          batch_size=bs,\n",
        "          epochs=10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1373.6080148661258\n",
            "51.90102381813943\n",
            "Model: \"functional_144\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_74 (InputLayer)        [(None, 3, 1, 3, 3)]      0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_5 (ConvLSTM2D)  (None, 1, 1, 64)          51712     \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_35 (RepeatVect (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "lstm_102 (LSTM)              (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 84,801\n",
            "Trainable params: 84,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.2727\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.1134\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.1017\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.1024\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0999\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0994\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.1070\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0951\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0965\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe9bba72ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVYVD-nJl5_D"
      },
      "source": [
        "why we are getting same results? It seems the randomness is introduced in `tensorflow` at a lot of stages and it is a complex function."
      ]
    }
  ]
}