{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "return_sequences_vs_return_states.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtrCheema/Miscellaneous_DL_Tutorials/blob/master/return_sequences_vs_return_states.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJfxAUz21Wu_",
        "colab_type": "text"
      },
      "source": [
        "## Intro\n",
        "This notebook describes difference between `return_sequence` and `return_state` arguments in LSTM/RNN layers of tensorflow/keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZgczBq1WvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c26fb08f-6f21-486d-e523-e44a2e0a3168"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Conv1D\n",
        "\n",
        "\n",
        "np.set_printoptions(suppress=True) # to suppress scientific notation while printing arrays\n",
        "\n",
        "def reset_graph(seed=313):\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2tWxsnv1WvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "427b6944-f1eb-48b2-a459-0f8e675d087d"
      },
      "source": [
        "seq_len = 10\n",
        "in_features = 3\n",
        "batch_size = 2\n",
        "units = 5\n",
        "\n",
        "# define input data\n",
        "data = np.random.normal(0,1, size=(batch_size, seq_len, in_features))\n",
        "print('input shape is', data.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape is (2, 10, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp12D59M1WvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3d3e99b3-dd18-4c43-94e6-8a8dd891fa81"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1 = LSTM(units)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# check output\n",
        "output = model.predict(data)\n",
        "print('output shape is ', output.shape)\n",
        "print(output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output shape is  (2, 5)\n",
            "[[-0.22040175 -0.05103757  0.11528992  0.19536228  0.05018005]\n",
            " [-0.15136391 -0.04078249  0.24475926  0.20049164  0.06182506]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfT_w2aF1Wvc",
        "colab_type": "text"
      },
      "source": [
        "### Return Sequence\n",
        "If we use `return_sequence=True`, we can get hidden state which is also output, at each time step instead of just one final output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zalJNpWz1Wvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "dfb835da-68f5-4f69-f88d-815766489fee"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "print('input shape is', data.shape)\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1 = LSTM(units, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# check output\n",
        "output = model.predict(data)\n",
        "print('output shape is ', output.shape)\n",
        "print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape is (2, 10, 3)\n",
            "output shape is  (2, 10, 5)\n",
            "[[[-0.24374452 -0.09573656  0.05246579  0.30608448 -0.00679237]\n",
            "  [ 0.03395621  0.12980539  0.02035871  0.15129386  0.04364523]\n",
            "  [ 0.13811205  0.21388356  0.02841143  0.02947732  0.18655203]\n",
            "  [ 0.19264422  0.24333045  0.04939342  0.02225473  0.1564781 ]\n",
            "  [-0.1532616  -0.07438491 -0.16188076  0.10787361 -0.05223484]\n",
            "  [-0.287893   -0.11108701 -0.01680756  0.2710228  -0.04088374]\n",
            "  [-0.07195782  0.02167981 -0.13415164  0.18494166 -0.19910014]\n",
            "  [-0.08962998  0.00878443  0.01223693  0.07652631  0.0050485 ]\n",
            "  [-0.27628472 -0.07134081  0.07844858  0.2543428   0.00744304]\n",
            "  [-0.22040175 -0.05103757  0.11528992  0.19536228  0.05018005]]\n",
            "\n",
            " [[ 0.08307333  0.05767366  0.11010146 -0.05327794  0.23188937]\n",
            "  [ 0.18589358  0.09882817  0.14136802  0.11742888  0.19913538]\n",
            "  [ 0.05701723  0.0274472   0.22920178  0.18271996  0.189026  ]\n",
            "  [-0.01641063 -0.06463264  0.13454576  0.24447107  0.09633702]\n",
            "  [-0.01751786 -0.02926924  0.16121973  0.14378461  0.15671824]\n",
            "  [-0.23319335 -0.1712274   0.18146896  0.29710758  0.01722185]\n",
            "  [-0.20075011 -0.18183641  0.11463575  0.16843669 -0.03972324]\n",
            "  [-0.07577026 -0.08698709  0.04348995  0.04353526 -0.0515892 ]\n",
            "  [-0.01021166  0.00229215  0.13523303 -0.00719722  0.12195523]\n",
            "  [-0.15136391 -0.04078249  0.24475926  0.20049164  0.06182506]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtuYWQnl1Wvi",
        "colab_type": "text"
      },
      "source": [
        "### Return States\n",
        "If we use `return_state=True`, it will give final hidden state/output plus the cell state as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsnu-bqv1Wvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "64300331-3ee2-4157-f88b-69952783f2a3"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1, state_h, state_c = LSTM(units, return_state=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
        "\n",
        "# check output\n",
        "_h, h, c = model.predict(data)\n",
        "print('_h: shape {} values \\n {}\\n'.format(_h.shape, _h))\n",
        "print('h: shape {} values \\n {}\\n'.format(h.shape, h))\n",
        "print('c: shape {} values \\n {}'.format(c.shape, c))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_h: shape (2, 5) values \n",
            " [[-0.22040175 -0.05103757  0.11528992  0.19536228  0.05018005]\n",
            " [-0.15136391 -0.04078249  0.24475926  0.20049164  0.06182506]]\n",
            "\n",
            "h: shape (2, 5) values \n",
            " [[-0.22040175 -0.05103757  0.11528992  0.19536228  0.05018005]\n",
            " [-0.15136391 -0.04078249  0.24475926  0.20049164  0.06182506]]\n",
            "\n",
            "c: shape (2, 5) values \n",
            " [[-0.44137242 -0.10972145  0.27500203  0.50635266  0.09567016]\n",
            " [-0.3063129  -0.13716078  0.42285413  0.5800175   0.26215786]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BU8SRTT1Wvn",
        "colab_type": "text"
      },
      "source": [
        "## using both at same time\n",
        "We can use both `return_sequences` and `return_states` at same time as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egq7f_aI1Wvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "7e70553d-ab2d-46b5-92f5-ba2215c5f9d7"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1, state_h, state_c = LSTM(units, return_state=True, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
        "\n",
        "# check output\n",
        "_h, h, c = model.predict(data)\n",
        "print('_h: shape {} values \\n {}\\n'.format(_h.shape, _h))\n",
        "print('h: shape {} values \\n {}\\n'.format(h.shape, h))\n",
        "print('c: shape {} values \\n {}'.format(c.shape, c))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_h: shape (2, 10, 5) values \n",
            " [[[-0.24374452 -0.09573656  0.05246579  0.30608448 -0.00679237]\n",
            "  [ 0.03395621  0.12980539  0.02035871  0.15129386  0.04364523]\n",
            "  [ 0.13811205  0.21388356  0.02841143  0.02947732  0.18655203]\n",
            "  [ 0.19264422  0.24333045  0.04939342  0.02225473  0.1564781 ]\n",
            "  [-0.1532616  -0.07438491 -0.16188076  0.10787361 -0.05223484]\n",
            "  [-0.287893   -0.11108701 -0.01680756  0.2710228  -0.04088374]\n",
            "  [-0.07195782  0.02167981 -0.13415164  0.18494166 -0.19910014]\n",
            "  [-0.08962998  0.00878443  0.01223693  0.07652631  0.0050485 ]\n",
            "  [-0.27628472 -0.07134081  0.07844858  0.2543428   0.00744304]\n",
            "  [-0.22040175 -0.05103757  0.11528992  0.19536228  0.05018005]]\n",
            "\n",
            " [[ 0.08307333  0.05767366  0.11010146 -0.05327794  0.23188937]\n",
            "  [ 0.18589358  0.09882817  0.14136802  0.11742888  0.19913538]\n",
            "  [ 0.05701723  0.0274472   0.22920178  0.18271996  0.189026  ]\n",
            "  [-0.01641063 -0.06463264  0.13454576  0.24447107  0.09633702]\n",
            "  [-0.01751786 -0.02926924  0.16121973  0.14378461  0.15671824]\n",
            "  [-0.23319335 -0.1712274   0.18146896  0.29710758  0.01722185]\n",
            "  [-0.20075011 -0.18183641  0.11463575  0.16843669 -0.03972324]\n",
            "  [-0.07577026 -0.08698709  0.04348995  0.04353526 -0.0515892 ]\n",
            "  [-0.01021166  0.00229215  0.13523303 -0.00719722  0.12195523]\n",
            "  [-0.15136391 -0.04078249  0.24475926  0.20049164  0.06182506]]]\n",
            "\n",
            "h: shape (2, 5) values \n",
            " [[-0.22040175 -0.05103757  0.11528992  0.19536228  0.05018005]\n",
            " [-0.15136391 -0.04078249  0.24475926  0.20049164  0.06182506]]\n",
            "\n",
            "c: shape (2, 5) values \n",
            " [[-0.44137242 -0.10972145  0.27500203  0.50635266  0.09567016]\n",
            " [-0.3063129  -0.13716078  0.42285413  0.5800175   0.26215786]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E652_Xij39zE",
        "colab_type": "text"
      },
      "source": [
        "##LSTM to 1D CNN\n",
        "\n",
        "We can put 1d cnn at the end of LSTM to further extract some features from LSTM output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQe42jl4DVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "39e39134-c48d-486c-95b8-8b1796ba6ae4"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "print('input shape is', data.shape)\n",
        "\n",
        "# define model\n",
        "inputs = Input(shape=(seq_len, in_features))\n",
        "lstm_layer = LSTM(units, return_sequences=True)\n",
        "lstm_outputs = lstm_layer(inputs)\n",
        "print('lstm output: ', lstm_outputs.shape)\n",
        "\n",
        "conv1 = Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(seq_len, units))(lstm_outputs)\n",
        "print('conv output: ', conv1.shape)\n",
        "\n",
        "max1d1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "print('max pool output: ', max1d1.shape)\n",
        "\n",
        "flat1 = Flatten()(max1d1)\n",
        "print('flatten output: ', flat1.shape)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=flat1)\n",
        "\n",
        "# check output\n",
        "output = model.predict(data)\n",
        "print('output shape: ', output.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape is (2, 10, 3)\n",
            "lstm output:  (None, 10, 5)\n",
            "conv output:  (None, 9, 64)\n",
            "max pool output:  (None, 4, 64)\n",
            "flatten output:  (None, 256)\n",
            "output shape:  (2, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPOkoHRg1Wvr",
        "colab_type": "text"
      },
      "source": [
        "## Credits\n",
        "This post is inspired from Jason Brownlee's [page](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/)"
      ]
    }
  ]
}