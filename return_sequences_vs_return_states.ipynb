{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "return_sequences_vs_return_states.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtrCheema/Miscellaneous_DL_Tutorials/blob/master/return_sequences_vs_return_states.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJfxAUz21Wu_",
        "colab_type": "text"
      },
      "source": [
        "## Intro\n",
        "This notebook describes difference between `return_sequence` and `return_state` arguments in LSTM/RNN layers of tensorflow/keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZgczBq1WvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "afdf64f2-f012-4375-c547-351b90ed4c5c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import MaxPooling1D, Flatten, Conv1D\n",
        "\n",
        "\n",
        "np.set_printoptions(suppress=True) # to suppress scientific notation while printing arrays\n",
        "\n",
        "def reset_graph(seed=313):\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    tf.compat.v1.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2tWxsnv1WvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cbff222-cf6e-4934-9d5d-deb59180ab23"
      },
      "source": [
        "seq_len = 10\n",
        "in_features = 3\n",
        "batch_size = 2\n",
        "units = 5\n",
        "\n",
        "# define input data\n",
        "data = np.random.normal(0,1, size=(batch_size, seq_len, in_features))\n",
        "print('input shape is', data.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape is (2, 10, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp12D59M1WvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "909ae798-bf73-448d-bb6d-5cd97bbe0c30"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1 = LSTM(units)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# check output\n",
        "output = model.predict(data)\n",
        "print('output shape is ', output.shape)\n",
        "print(output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output shape is  (2, 5)\n",
            "[[-0.1566722  -0.09671225 -0.07435499  0.2380382  -0.10205627]\n",
            " [ 0.0498487   0.10540111 -0.11872431  0.21326743 -0.07617775]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfT_w2aF1Wvc",
        "colab_type": "text"
      },
      "source": [
        "### Return Sequence\n",
        "If we use `return_sequence=True`, we can get hidden state which is also output, at each time step instead of just one final output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zalJNpWz1Wvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "8887275e-0a31-4ed0-c0b4-efa108f17992"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "print('input shape is', data.shape)\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1 = LSTM(units, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# check output\n",
        "output = model.predict(data)\n",
        "print('output shape is ', output.shape)\n",
        "print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape is (2, 10, 3)\n",
            "output shape is  (2, 10, 5)\n",
            "[[[-0.02143264 -0.00227202  0.06692377  0.03960254  0.06273782]\n",
            "  [ 0.11968565  0.08252696  0.09503155  0.0289942   0.17401429]\n",
            "  [ 0.10317614  0.03702856  0.16926843  0.06439783  0.24887747]\n",
            "  [ 0.25664562  0.21938275  0.0558738   0.03023281  0.17119098]\n",
            "  [ 0.10064318  0.04220012  0.15114217  0.22362679  0.03877142]\n",
            "  [ 0.04813049  0.06628726  0.09269002  0.21057403  0.16603518]\n",
            "  [-0.06222967 -0.02064434  0.05820563  0.17465067  0.06314038]\n",
            "  [-0.0490917  -0.07563521 -0.07562283  0.1867909  -0.07249714]\n",
            "  [-0.0628821  -0.13354729 -0.24176472  0.13450752 -0.2201733 ]\n",
            "  [-0.1566722  -0.09671225 -0.07435499  0.2380382  -0.10205627]]\n",
            "\n",
            " [[-0.06512719 -0.12316308 -0.23606628 -0.09947219 -0.19536504]\n",
            "  [-0.24930197 -0.31348827 -0.31217012  0.03622868 -0.14607252]\n",
            "  [-0.24061005 -0.22410582 -0.08258545  0.14922056 -0.16823886]\n",
            "  [-0.07348045 -0.09826367 -0.13519506  0.0518603  -0.24591225]\n",
            "  [-0.10792634 -0.08394783 -0.06631595  0.12301818 -0.12757494]\n",
            "  [-0.0303727   0.01570306 -0.11690737 -0.00810247 -0.12978283]\n",
            "  [ 0.09066503  0.1769065  -0.27474576 -0.11087675 -0.29330632]\n",
            "  [-0.00410285  0.05030951 -0.3666474  -0.08758772 -0.25567603]\n",
            "  [ 0.18652098  0.22879124 -0.16318311 -0.0619657  -0.25020158]\n",
            "  [ 0.0498487   0.10540111 -0.11872431  0.21326743 -0.07617775]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtuYWQnl1Wvi",
        "colab_type": "text"
      },
      "source": [
        "### Return States\n",
        "If we use `return_state=True`, it will give final hidden state/output plus the cell state as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsnu-bqv1Wvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "ff52d8e0-cb79-4c5e-e9ec-f52ee8253d0a"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1, state_h, state_c = LSTM(units, return_state=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
        "\n",
        "# check output\n",
        "_h, h, c = model.predict(data)\n",
        "print('_h: shape {} values \\n {}\\n'.format(_h.shape, _h))\n",
        "print('h: shape {} values \\n {}\\n'.format(h.shape, h))\n",
        "print('c: shape {} values \\n {}'.format(c.shape, c))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_h: shape (2, 5) values \n",
            " [[-0.1566722  -0.09671225 -0.07435499  0.2380382  -0.10205627]\n",
            " [ 0.0498487   0.10540111 -0.11872431  0.21326743 -0.07617775]]\n",
            "\n",
            "h: shape (2, 5) values \n",
            " [[-0.1566722  -0.09671225 -0.07435499  0.2380382  -0.10205627]\n",
            " [ 0.0498487   0.10540111 -0.11872431  0.21326743 -0.07617775]]\n",
            "\n",
            "c: shape (2, 5) values \n",
            " [[-0.29146802 -0.22284117 -0.17079654  0.5928285  -0.2525362 ]\n",
            " [ 0.07988599  0.1933969  -0.30316094  0.4730413  -0.22530162]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BU8SRTT1Wvn",
        "colab_type": "text"
      },
      "source": [
        "## using both at same time\n",
        "We can use both `return_sequences` and `return_states` at same time as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egq7f_aI1Wvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "130d4787-5046-4744-80b2-863c4942c1df"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# define model\n",
        "inputs1 = Input(shape=(seq_len, in_features))\n",
        "lstm1, state_h, state_c = LSTM(units, return_state=True, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=[lstm1, state_h, state_c])\n",
        "\n",
        "# check output\n",
        "_h, h, c = model.predict(data)\n",
        "print('_h: shape {} values \\n {}\\n'.format(_h.shape, _h))\n",
        "print('h: shape {} values \\n {}\\n'.format(h.shape, h))\n",
        "print('c: shape {} values \\n {}'.format(c.shape, c))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_h: shape (2, 10, 5) values \n",
            " [[[-0.02143264 -0.00227202  0.06692377  0.03960254  0.06273782]\n",
            "  [ 0.11968565  0.08252696  0.09503155  0.0289942   0.17401429]\n",
            "  [ 0.10317614  0.03702856  0.16926843  0.06439783  0.24887747]\n",
            "  [ 0.25664562  0.21938275  0.0558738   0.03023281  0.17119098]\n",
            "  [ 0.10064318  0.04220012  0.15114217  0.22362679  0.03877142]\n",
            "  [ 0.04813049  0.06628726  0.09269002  0.21057403  0.16603518]\n",
            "  [-0.06222967 -0.02064434  0.05820563  0.17465067  0.06314038]\n",
            "  [-0.0490917  -0.07563521 -0.07562283  0.1867909  -0.07249714]\n",
            "  [-0.0628821  -0.13354729 -0.24176472  0.13450752 -0.2201733 ]\n",
            "  [-0.1566722  -0.09671225 -0.07435499  0.2380382  -0.10205627]]\n",
            "\n",
            " [[-0.06512719 -0.12316308 -0.23606628 -0.09947219 -0.19536504]\n",
            "  [-0.24930197 -0.31348827 -0.31217012  0.03622868 -0.14607252]\n",
            "  [-0.24061005 -0.22410582 -0.08258545  0.14922056 -0.16823886]\n",
            "  [-0.07348045 -0.09826367 -0.13519506  0.0518603  -0.24591225]\n",
            "  [-0.10792634 -0.08394783 -0.06631595  0.12301818 -0.12757494]\n",
            "  [-0.0303727   0.01570306 -0.11690737 -0.00810247 -0.12978283]\n",
            "  [ 0.09066503  0.1769065  -0.27474576 -0.11087675 -0.29330632]\n",
            "  [-0.00410285  0.05030951 -0.3666474  -0.08758772 -0.25567603]\n",
            "  [ 0.18652098  0.22879124 -0.16318311 -0.0619657  -0.25020158]\n",
            "  [ 0.0498487   0.10540111 -0.11872431  0.21326743 -0.07617775]]]\n",
            "\n",
            "h: shape (2, 5) values \n",
            " [[-0.1566722  -0.09671225 -0.07435499  0.2380382  -0.10205627]\n",
            " [ 0.0498487   0.10540111 -0.11872431  0.21326743 -0.07617775]]\n",
            "\n",
            "c: shape (2, 5) values \n",
            " [[-0.29146802 -0.22284117 -0.17079654  0.5928285  -0.2525362 ]\n",
            " [ 0.07988599  0.1933969  -0.30316094  0.4730413  -0.22530162]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E652_Xij39zE",
        "colab_type": "text"
      },
      "source": [
        "##LSTM to 1D CNN\n",
        "\n",
        "We can put 1d cnn at the end of LSTM to further extract some features from LSTM output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQe42jl4DVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "68065aa7-555b-41fa-ded9-0780bdd9aca9"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "print('input shape is', data.shape)\n",
        "\n",
        "# define model\n",
        "inputs = Input(shape=(seq_len, in_features))\n",
        "lstm_layer = LSTM(units, return_sequences=True)\n",
        "lstm_outputs = lstm_layer(inputs)\n",
        "print('lstm output: ', lstm_outputs.shape)\n",
        "\n",
        "conv1 = Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(seq_len, units))(lstm_outputs)\n",
        "print('conv output: ', conv1.shape)\n",
        "\n",
        "max1d1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "print('max pool output: ', max1d1.shape)\n",
        "\n",
        "flat1 = Flatten()(max1d1)\n",
        "print('flatten output: ', flat1.shape)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=flat1)\n",
        "\n",
        "# check output\n",
        "output = model.predict(data)\n",
        "print('output shape: ', output.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape is (2, 10, 3)\n",
            "lstm output:  (None, 10, 5)\n",
            "conv output:  (None, 9, 64)\n",
            "max pool output:  (None, 4, 64)\n",
            "flatten output:  (None, 256)\n",
            "output shape:  (2, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nnGF7Yo0yyf",
        "colab_type": "text"
      },
      "source": [
        "The output from LSTM/RNN looks roughly as below.\n",
        "$$ \n",
        "h_t = tanh(b + Wh_{t-1} + UX_t)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HDxDDFi0XI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e6e64821-7a1d-4878-a299-455b63e25715"
      },
      "source": [
        "print('kernel U: ', lstm_layer.get_weights()[0].shape)  # weights of our input against every neuron in LSTM\n",
        "print('recurrent kernel, W: ', lstm_layer.get_weights()[1].shape) # weights of our hidden state a.k.a the output of LSTM in the previous timestep (t-1) against every neuron in LSTM\n",
        "print('bias: ', lstm_layer.get_weights()[2].shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kernel:  (3, 20)\n",
            "recurrent kernel:  (5, 20)\n",
            "bias:  (20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPOkoHRg1Wvr",
        "colab_type": "text"
      },
      "source": [
        "## Credits\n",
        "This post is inspired from Jason Brownlee's [page](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/)"
      ]
    }
  ]
}